{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture SNP500 companies data & put symbols in a list ##\n",
    "\n",
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "payload=pd.read_html('https://en.wikipedia.org/wiki/S%26P_100')\n",
    "first_table = payload[0]\n",
    "second_table = payload[1]\n",
    "third_table = payload[2]\n",
    "\n",
    "df = third_table\n",
    "symbols = df['Symbol'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hit AlphaVantage API for 1 minute interval prices and insert into csvs ##\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def price_wrapper(tickers):\n",
    "\n",
    "    file_list =[]    \n",
    "    for x in tickers:\n",
    "        CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol='+x+'&interval=1min&slice=year1month1&apikey=VOTCB8UWEES6J5NP'\n",
    "        \n",
    "        with requests.Session() as s:\n",
    "            download = s.get(CSV_URL)\n",
    "            decoded_content = download.content.decode('utf-8')\n",
    "            cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "            my_list = list(cr)\n",
    "            \n",
    "            ##append column with symbol\n",
    "            my_list[0].insert(0,'symbol')\n",
    "            for row in my_list[1:(len(my_list)-1)]:\n",
    "                row.insert(0,x)\n",
    "            \n",
    "            file = \"/YXRwLW5vdGVib29rLXN0cHluZS1zZXNzaW9uLWpydWw=/stpyne/symbols_prices_new/\"+x+\".csv\"\n",
    "            \n",
    "            file_list.append(file)\n",
    "            \n",
    "            with open(file, 'w') as csvfile: \n",
    "                csvwriter = csv.writer(csvfile) \n",
    "                csvwriter.writerow(my_list[0])\n",
    "                for row in my_list[1:(len(my_list)-1)]:\n",
    "                    csvwriter.writerow(row)\n",
    "        \n",
    "        #use sleep to ensure do not max out 5 API calls per minute\n",
    "        time.sleep(60)\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "##Twitter API Auth Setup\n",
    "\n",
    "consumer_key= '6jvo5IFoAAoLLznFVJm6xb1N1'\n",
    "consumer_secret= 'UqAipjwJUPrOVE0tLOHoqPFaxA4ZKpWRvENJrlknK2AJKGsr5u'\n",
    "access_token= '1422620267059183618-bOU2AlKVbb8UU9HeBg1g87YaWcyCRj'\n",
    "access_token_secret= 'fAhSJD3l0AYt4FKvJU7V9zYkWOfcg7RNksVkdqcCAZOAT'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query Twitter API \n",
    "\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "countlist = []\n",
    "tweetcount= 0\n",
    "diff=0\n",
    "with open ('symbols_tweets_upd1.csv', 'a+', newline='',encoding='utf-8') as csvFile:\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow(['symbol','tweet_id','text','created_at','retweets','likes','geo','place','coordinates','location'])                     \n",
    "    \n",
    "    \n",
    "    for symbol in symbols:\n",
    "        if len(countlist) > 15000 and diff<500 and diff <900:\n",
    "            print('max api reached. total tweets:' + str(tweetcount) +\" -- seconds elapsed:\"+str(diff)+\"....sleeping\")\n",
    "            time.sleep(700)\n",
    "            diff = 0\n",
    "            countlist = []\n",
    "        else:\n",
    "            print('total tweets queried so far:' + str(tweetcount) +\" -- seconds elapsed:\"+str(diff)+\"...running\")\n",
    "        \n",
    "            \n",
    "        tic = time.perf_counter()\n",
    "        print(symbol+' start')\n",
    "        \n",
    "        for tweet in tw.Cursor(api.search,\n",
    "                           q = \"$\" + symbol,\n",
    "                           until = \"2021-08-7\",\n",
    "                           lang = \"en\",\n",
    "                              ).items(4000):\n",
    "           \n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "            tweets_encoded = tweet.text.encode('utf-8')\n",
    "            tweets_decoded = tweets_encoded.decode('utf-8')\n",
    "                        \n",
    "            csvWriter.writerow([symbol, tweet.id, tweets_decoded, tweet.created_at,tweet.retweet_count, tweet.favorite_count, tweet.geo, tweet.place.name if tweet.place else None, tweet.coordinates, tweet._json[\"user\"][\"location\"]])\n",
    "            countlist.append(tweet.id)\n",
    "        print(symbol + \" finish\")\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        diff = diff + (toc - tic)\n",
    "        tweetcount = len(countlist)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "spark = SparkSession(sc)    \n",
    "df = spark.read.load(\"symbols_tweets_mod.csv\",\n",
    "                     format=\"csv\", sep=\",\", header=\"true\",multiline=\"true\")\n",
    "\n",
    "df_upd = df.where(length(col(\"symbol\")) <= 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(symbol,IntegerType,true),StructField(tweet_id,StringType,true),StructField(text,StringType,true),StructField(created_at,StringType,true),StructField(retweets,StringType,true),StructField(likes,StringType,true),StructField(geo,StringType,true),StructField(place,StringType,true),StructField(coordinates,StringType,true),StructField(location,StringType,true)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##getting weird error \"likes\" is not a numeric column. come back to this....\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "df_upd = df_upd.withColumn(\"symbol\", df_upd[\"symbol\"].cast(IntegerType()))\n",
    "df_upd.schema\n",
    "\n",
    "#df_upd.groupBy(\"symbol\").sum(\"likes\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-11-08f1dda56af9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-08f1dda56af9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_upd.groupBy(‘symbol’).count().show()\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_upd.groupBy(‘symbol’).count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upd.toPandas()['k'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
